{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting all the stereotype tokens in the dataset for region and religion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = '../../nlp-fairness-for-india'\n",
    "\n",
    "utils_folder = '../../utils'\n",
    "os.makedirs(utils_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of region tokens: 139\n",
      "Number of religion tokens: 216\n"
     ]
    }
   ],
   "source": [
    "axes = ['region', 'religion']\n",
    "\n",
    "for axis in axes:\n",
    "    tokens_set = set()\n",
    "    with open(f'{dataset_folder}/{axis}_annotations.tsv', 'r') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if row[0] == 'identity_term':\n",
    "                continue\n",
    "            tokens_set.add(row[1])\n",
    "    \n",
    "    print(f'Number of {axis} tokens: {len(tokens_set)}')\n",
    "\n",
    "    with open(f'{utils_folder}/{axis}_tokens.txt', 'w') as f:\n",
    "        for token in tokens_set:\n",
    "            f.write(f'{token}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annotating the tokens to reflect the subcategory they belong to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process was carried out with the help of Gemini 2.0 and after that I had manually checked the results to ensure that the tokens were correctly annotated.\n",
    "\n",
    "It should be noted that due to this automatic annotation process there were some issues like the very low number of of tokens being classified into the category of food or clothes. \n",
    "\n",
    "The annotations were stored in the form of a csv into ```region_annotated.csv``` and ```religion_annotated.csv```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categories for region: ['adjectives', 'subjects', 'professions', 'verbs', 'offensive_terms', 'food']\n",
      "adjectives: 35\n",
      "subjects: 19\n",
      "professions: 81\n",
      "verbs: 2\n",
      "offensive_terms: 1\n",
      "food: 1\n",
      "Categories for religion: ['professions', 'adjectives', 'subjects', 'verbs', 'offensive_terms', 'socio-economic_status']\n",
      "professions: 141\n",
      "adjectives: 46\n",
      "subjects: 20\n",
      "verbs: 6\n",
      "offensive_terms: 2\n",
      "socio-economic_status: 1\n"
     ]
    }
   ],
   "source": [
    "for axis in axes:\n",
    "    category_count = {}\n",
    "    with open(f'{utils_folder}/{axis}_annotated.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if row[0] == 'category':\n",
    "                continue\n",
    "            category = row[0]\n",
    "            if category not in category_count:\n",
    "                category_count[category] = 0\n",
    "            category_count[category] += 1\n",
    "\n",
    "    print(f'Categories for {axis}: {[category for category in category_count]}')\n",
    "    # display the number of for each category\n",
    "    for category, count in category_count.items():\n",
    "        print(f'{category}: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling the final dataset with annotated tokens for each identity terms, along with their stereotype category and annotation confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_annotations = {}\n",
    "\n",
    "for axis in axes:\n",
    "    token_annotations[axis] = {}\n",
    "    with open(f'{utils_folder}/{axis}_annotated.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            if row[0] == 'category':\n",
    "                continue\n",
    "            token_annotations[axis][row[1]] = row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for axis in axes:\n",
    "    compiled_data = {}\n",
    "    with open(f'{dataset_folder}/{axis}_annotations.tsv', 'r') as f:\n",
    "        reader = csv.reader(f, delimiter='\\t')\n",
    "        for row in reader:\n",
    "            if row[0] == 'identity_term':\n",
    "                continue\n",
    "            \n",
    "            identity_term = row[0]\n",
    "            identity_term = identity_term[0].upper() + identity_term[1:]\n",
    "\n",
    "            token = row[1]\n",
    "            stereotype_votes = int(row[2])\n",
    "            non_stereotype_votes = int(row[3])\n",
    "            total_votes = int(row[5])\n",
    "\n",
    "            if stereotype_votes > non_stereotype_votes:\n",
    "                stereotype = True\n",
    "                annotation_confidence = stereotype_votes / total_votes if total_votes > 0 else 0\n",
    "            else:\n",
    "                stereotype = False\n",
    "                annotation_confidence = non_stereotype_votes / total_votes if total_votes > 0 else 0\n",
    "            \n",
    "            if identity_term not in compiled_data:\n",
    "                compiled_data[identity_term] = []\n",
    "\n",
    "            compiled_data[identity_term].append({\n",
    "                'token': token,\n",
    "                'stereotype': stereotype,\n",
    "                'annotation_confidence': annotation_confidence,\n",
    "                'annotation': token_annotations[axis].get(token, None)\n",
    "            })    \n",
    "    \n",
    "    json.dump(compiled_data, open(f'{utils_folder}/all_{axis}_data.json', 'w'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
